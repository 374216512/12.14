{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_labels(file):\n",
    "    with open(file, \"rb\") as f:\n",
    "        data = f.read()\n",
    "    \n",
    "    magic_number, num_samples = struct.unpack(\">ii\", data[:8])\n",
    "    if magic_number != 2049:   # 0x00000801\n",
    "        print(f\"magic number mismatch {magic_number} != 2049\")\n",
    "        return None\n",
    "    \n",
    "    labels = np.frombuffer(data[8:], dtype=np.uint8)\n",
    "    return labels\n",
    "\n",
    "def load_images(file):\n",
    "    with open(file, \"rb\") as f:\n",
    "        data = f.read()\n",
    "\n",
    "    magic_number, num_samples, image_width, image_height = struct.unpack(\">iiii\", data[:16])\n",
    "    if magic_number != 2051:   # 0x00000803\n",
    "        print(f\"magic number mismatch {magic_number} != 2051\")\n",
    "        return None\n",
    "    \n",
    "    image_data = np.frombuffer(data[16:], dtype=np.uint8).reshape(num_samples, -1)\n",
    "    return image_data\n",
    "\n",
    "def one_hot(labels, classes, label_smoothing=0):\n",
    "    n = len(labels)\n",
    "    eoff = label_smoothing / classes\n",
    "    output = np.ones((n, classes), dtype=np.float32) * eoff\n",
    "    for row, label in enumerate(labels):\n",
    "        output[row, label] = 1 - label_smoothing + eoff\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset/t10k-labels-idx1-ubyte'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-3-97279b5a0ff9>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mval_labels\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mload_labels\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"dataset/t10k-labels-idx1-ubyte\"\u001B[0m\u001B[1;33m)\u001B[0m   \u001B[1;31m#  10000,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mval_images\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mload_images\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"dataset/t10k-images-idx3-ubyte\"\u001B[0m\u001B[1;33m)\u001B[0m   \u001B[1;31m#  10000, 784\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mval_images\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mval_images\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mval_images\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m/\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mvar\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mval_images\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;31m#val_images = val_images / 255 - 0.5\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mval_images\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mval_images\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m28\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m28\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-2-46a8bef42007>\u001B[0m in \u001B[0;36mload_labels\u001B[1;34m(file)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mload_labels\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfile\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m     \u001B[1;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfile\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"rb\"\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m         \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0mmagic_number\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnum_samples\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mstruct\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0munpack\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\">ii\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;36m8\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'dataset/t10k-labels-idx1-ubyte'"
     ]
    }
   ],
   "source": [
    "val_labels = load_labels(\"dataset/t10k-labels-idx1-ubyte\")   #  10000,\n",
    "val_images = load_images(\"dataset/t10k-images-idx3-ubyte\")   #  10000, 784\n",
    "val_images = (val_images - np.mean(val_images)) / np.var(val_images)\n",
    "#val_images = val_images / 255 - 0.5\n",
    "val_images = val_images.reshape(-1, 1, 28, 28)\n",
    "\n",
    "train_labels = load_labels(\"dataset/train-labels-idx1-ubyte\") # 60000,\n",
    "train_images = load_images(\"dataset/train-images-idx3-ubyte\") # 60000, 784\n",
    "#train_images = train_images / 255 - 0.5\n",
    "train_images = (train_images - np.mean(train_images)) / np.var(train_images)\n",
    "train_images = train_images.reshape(-1, 1, 28, 28)\n",
    "#train_images = (train_images - np.mean(train_images)) / np.var(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.min(val_images), np.max(val_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        \n",
    "    # 获取他的一个item，  dataset = Dataset(),   dataset[index]\n",
    "    def __getitem__(self, index):\n",
    "        return self.images[index].reshape(1, 1, 28, 28), self.labels[index]\n",
    "    \n",
    "    # 获取数据集的长度，个数\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "class DataLoaderIterator:\n",
    "    def __init__(self, dataloader):\n",
    "        self.dataloader = dataloader\n",
    "        self.cursor = 0\n",
    "        self.indexs = list(range(self.dataloader.count_data))  # 0, ... 60000\n",
    "        if self.dataloader.shuffle:\n",
    "            # 打乱一下\n",
    "            np.random.shuffle(self.indexs)\n",
    "            \n",
    "    def __next__(self):\n",
    "        if self.cursor >= self.dataloader.count_data:\n",
    "            raise StopIteration()\n",
    "            \n",
    "        batch_data = []\n",
    "        remain = min(self.dataloader.batch_size, self.dataloader.count_data - self.cursor)  #  256, 128\n",
    "        for n in range(remain):\n",
    "            index = self.indexs[self.cursor]\n",
    "            data = self.dataloader.dataset[index]\n",
    "            \n",
    "            # 如果batch没有初始化，则初始化n个list成员\n",
    "            if len(batch_data) == 0:\n",
    "                batch_data = [[] for i in range(len(data))]\n",
    "                \n",
    "            #直接append进去\n",
    "            for index, item in enumerate(data):\n",
    "                batch_data[index].append(item)\n",
    "            self.cursor += 1\n",
    "            \n",
    "        # 通过np.vstack一次性实现合并，而非每次一直在合并\n",
    "        for index in range(len(batch_data)):\n",
    "            batch_data[index] = np.vstack(batch_data[index])\n",
    "        return batch_data\n",
    "\n",
    "class DataLoader:\n",
    "    \n",
    "    # shuffle 打乱\n",
    "    def __init__(self, dataset, batch_size, shuffle):\n",
    "        self.dataset = dataset\n",
    "        self.shuffle = shuffle\n",
    "        self.count_data = len(dataset)\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return DataLoaderIterator(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.random.binomial(size=(10, 10), p=0.1, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Module:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.train_mode = False\n",
    "        \n",
    "    def __call__(self, *args):\n",
    "        return self.forward(*args)\n",
    "    \n",
    "    def train(self):\n",
    "        self.train_mode = True\n",
    "        for m in self.modules():\n",
    "            m.train()\n",
    "        \n",
    "    def eval(self):\n",
    "        self.train_mode = False\n",
    "        for m in self.modules():\n",
    "            m.eval()\n",
    "        \n",
    "    def modules(self):\n",
    "        ms = []\n",
    "        for attr in self.__dict__:\n",
    "            m = self.__dict__[attr]\n",
    "            if isinstance(m, Module):\n",
    "                ms.append(m)\n",
    "        return ms\n",
    "    \n",
    "    def params(self):\n",
    "        ps = []\n",
    "        for attr in self.__dict__:\n",
    "            p = self.__dict__[attr]\n",
    "            if isinstance(p, Parameter):\n",
    "                ps.append(p)\n",
    "            \n",
    "        ms = self.modules()\n",
    "        for m in ms:\n",
    "            ps.extend(m.params())\n",
    "        return ps\n",
    "    \n",
    "    def info(self, n):\n",
    "        ms = self.modules()\n",
    "        output = f\"{self.name}\\n\"\n",
    "        for m in ms:\n",
    "            output += ('  '*(n+1)) + f\"{m.info(n+1)}\\n\"\n",
    "        return output[:-1]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.info(0)\n",
    "    \n",
    "class Initializer:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        \n",
    "    def __call__(self, *args):\n",
    "        return self.apply(*args)\n",
    "        \n",
    "class GaussInitializer(Initializer):\n",
    "    # where :math:`\\mu` is the mean and :math:`\\sigma` the standard\n",
    "    # deviation. The square of the standard deviation, :math:`\\sigma^2`,\n",
    "    # is called the variance.\n",
    "    def __init__(self, mu, sigma):\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def apply(self, value):\n",
    "        value[...] = np.random.normal(self.mu, self.sigma, value.shape)\n",
    "    \n",
    "class Parameter:\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "        self.delta = np.zeros(value.shape)\n",
    "        \n",
    "    def zero_grad(self):\n",
    "        self.delta[...] = 0\n",
    "        \n",
    "class Linear(Module):\n",
    "    def __init__(self, input_feature, output_feature):\n",
    "        super().__init__(\"Linear\")\n",
    "        self.input_feature = input_feature\n",
    "        self.output_feature = output_feature\n",
    "        self.weights = Parameter(np.zeros((input_feature, output_feature)))\n",
    "        self.bias = Parameter(np.zeros((1, output_feature)))\n",
    "        \n",
    "        # 权重初始化 \n",
    "        initer = GaussInitializer(0, np.sqrt(2 / input_feature))  # np.sqrt(2 / input_feature)\n",
    "        initer.apply(self.weights.value)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x_save = x.copy()\n",
    "        return x @ self.weights.value + self.bias.value\n",
    "    \n",
    "    #AB = C  G\n",
    "    #dB = A.T @ G\n",
    "    #dA = G @ B.T\n",
    "    def backward(self, G):\n",
    "        self.weights.delta += self.x_save.T @ G\n",
    "        self.bias.delta += np.sum(G, 0)  #值复制\n",
    "        return G @ self.weights.value.T\n",
    "    \n",
    "class ReLU(Module):\n",
    "    def __init__(self, inplace=True):\n",
    "        super().__init__(\"ReLU\")\n",
    "        self.inplace = inplace\n",
    "        \n",
    "    # 亿点点\n",
    "    def forward(self, x):\n",
    "        self.negative_position = x < 0\n",
    "        if not self.inplace:\n",
    "            x = x.copy()\n",
    "            \n",
    "        x[self.negative_position] = 0\n",
    "        return x\n",
    "    \n",
    "    def backward(self, G):\n",
    "        if not self.inplace:\n",
    "            G = G.copy()\n",
    "            \n",
    "        G[self.negative_position] = 0\n",
    "        return G\n",
    "\n",
    "def sigmoid(x):\n",
    "    p0 = x < 0\n",
    "    p1 = ~p0\n",
    "    x = x.copy()\n",
    "\n",
    "    # 如果x的类型是整数，那么会造成丢失精度\n",
    "    x[p0] = np.exp(x[p0]) / (1 + np.exp(x[p0]))\n",
    "    x[p1] = 1 / (1 + np.exp(-x[p1]))\n",
    "    return x\n",
    "\n",
    "class SWish(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"SWish\")\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x_save = x.copy()\n",
    "        self.sx = sigmoid(x)\n",
    "        return x * self.sx\n",
    "    \n",
    "    def backward(self, G):\n",
    "        return G * (self.sx + self.x_save * self.sx * (1 - self.sx))\n",
    "    \n",
    "class Dropout(Module):\n",
    "    def __init__(self, prob_keep=0.5, inplace=True):\n",
    "        super().__init__(\"Dropout\")\n",
    "        self.prob_keep = prob_keep\n",
    "        self.inplace = inplace\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if not self.train_mode:\n",
    "            return x\n",
    "        \n",
    "        self.mask = np.random.binomial(size=x.shape, p=1 - self.prob_keep, n=1)\n",
    "        if not self.inplace:\n",
    "            x = x.copy()\n",
    "            \n",
    "        x[self.mask] = 0\n",
    "        x *= 1 / self.prob_keep  # rescale\n",
    "        return x\n",
    "    \n",
    "    def backward(self, G):\n",
    "        if not self.inplace:\n",
    "            G = G.copy()\n",
    "        G[self.mask] = 0\n",
    "        G *= 1 / self.prob_keep\n",
    "        return G\n",
    "    \n",
    "class Conv2d(Module):\n",
    "    def __init__(self, in_feature, out_feature, kernel_size, padding=0, stride=1):\n",
    "        super().__init__(\"Conv2d\")\n",
    "        self.in_feature = in_feature\n",
    "        self.out_feature = out_feature\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        self.stride = stride\n",
    "        self.kernel = Parameter(np.ones((out_feature, in_feature, kernel_size, kernel_size)))\n",
    "        self.bias = Parameter(np.zeros((out_feature)))\n",
    "        initer = GaussInitializer(0, np.sqrt(2 / in_feature))  # np.sqrt(2 / input_feature)\n",
    "        initer.apply(self.kernel.value)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.in_shape = x.shape\n",
    "        ib, ic, ih, iw = self.in_shape\n",
    "        self.oh = (ih + self.padding * 2 - self.kernel_size) // self.stride + 1\n",
    "        self.ow = (iw + self.padding * 2 - self.kernel_size) // self.stride + 1\n",
    "        col_w = self.oh * self.ow\n",
    "        col_h = self.kernel_size * self.kernel_size * self.in_feature\n",
    "        self.column = np.zeros((ib, col_h, col_w))\n",
    "        self.output = np.zeros((ib, self.out_feature, self.oh, self.ow))\n",
    "        khalf = self.kernel_size // 2\n",
    "        self.kcol = self.kernel.value.reshape(self.out_feature, -1)\n",
    "        for b in range(ib):\n",
    "            for c in range(ic):\n",
    "                for oy in range(self.oh):\n",
    "                    for ox in range(self.ow):\n",
    "                        for ky in range(self.kernel_size):\n",
    "                            for kx in range(self.kernel_size):\n",
    "                                column_y = ky * self.kernel_size + kx + c * self.kernel_size * self.kernel_size\n",
    "                                column_x = ox + oy * self.ow\n",
    "                                ix = ox * self.stride + kx - self.padding\n",
    "                                iy = oy * self.stride + ky - self.padding\n",
    "                                if ix >= 0 and iy >= 0 and ix < iw and iy < ih:\n",
    "                                    self.column[b, column_y, column_x] = x[b, c, iy, ix]\n",
    "            self.output[b] = (self.kcol @ self.column[b]).reshape(self.out_feature, self.oh, self.ow) + self.bias.value.reshape(self.out_feature, 1, 1)\n",
    "        return self.output\n",
    "    \n",
    "    #AB = C  G\n",
    "    #dB = A.T @ G\n",
    "    #dA = G @ B.T\n",
    "    def backward(self, G):\n",
    "        \n",
    "        ib, ic, ih, iw = self.in_shape\n",
    "        for b in range(ib):\n",
    "            self.kernel.delta += (G[b].reshape(self.out_feature, -1) @ self.column[b].T).reshape(self.kernel.value.shape)\n",
    "    \n",
    "        self.bias.delta += np.sum(G, axis=(0, 2, 3))\n",
    "        self.Gout = np.zeros((self.in_shape))\n",
    "        for b in range(ib):\n",
    "            dcolumn = self.kcol.T @ G[b].reshape(self.out_feature, -1)\n",
    "            \n",
    "            for c in range(ic):\n",
    "                for oy in range(self.oh):\n",
    "                    for ox in range(self.ow):\n",
    "                        for ky in range(self.kernel_size):\n",
    "                            for kx in range(self.kernel_size):\n",
    "                                column_y = ky * self.kernel_size + kx + c * self.kernel_size * self.kernel_size\n",
    "                                column_x = ox + oy * self.ow\n",
    "                                ix = ox * self.stride + kx - self.padding\n",
    "                                iy = oy * self.stride + ky - self.padding\n",
    "                                if ix >= 0 and iy >= 0 and ix < iw and iy < ih:\n",
    "                                    self.Gout[b, c, iy, ix] += dcolumn[column_y, column_x]\n",
    "        return self.Gout\n",
    "    \n",
    "class Flatten(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"Flatten\")\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.in_shape = x.shape\n",
    "        out = x.reshape(self.in_shape[0], -1)\n",
    "        return out\n",
    "    \n",
    "    def backward(self, G):\n",
    "        return G.reshape(self.in_shape)\n",
    "    \n",
    "class ModuleList(Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__(\"ModuleList\")\n",
    "        self.ms = list(args)\n",
    "        \n",
    "    def modules(self):\n",
    "        return self.ms\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for m in self.ms:\n",
    "            x = m(x)\n",
    "        return x\n",
    "    \n",
    "    def backward(self, G):\n",
    "        for i in range(len(self.ms)-1, -1, -1):\n",
    "            G = self.ms[i].backward(G)\n",
    "        return G\n",
    "    \n",
    "class SigmoidCrossEntropy(Module):\n",
    "    def __init__(self, params, weight_decay=1e-5):\n",
    "        super().__init__(\"CrossEntropyLoss\")\n",
    "        self.params = params\n",
    "        self.weight_decay = weight_decay\n",
    "        \n",
    "    def sigmoid(self, x):\n",
    "        #return 1 / (1 + np.exp(-x))\n",
    "        p0 = x < 0\n",
    "        p1 = ~p0\n",
    "        x = x.copy()\n",
    "        x[p0] = np.exp(x[p0]) / (1 + np.exp(x[p0]))\n",
    "        x[p1] = 1 / (1 + np.exp(-x[p1]))\n",
    "        return x\n",
    "    \n",
    "    def decay_loss(self):\n",
    "        loss = 0\n",
    "        for p in self.params:\n",
    "            loss += np.sqrt(np.sum(p.value ** 2)) / (2 * p.value.size) * self.weight_decay\n",
    "        return loss\n",
    "    \n",
    "    def decay_backward(self):\n",
    "        for p in self.params:\n",
    "            eps = 1e-8\n",
    "            p.delta += 1 / (2 * np.sqrt(np.sum(p.value ** 2)) + eps) / (2 * p.value.size) * self.weight_decay * 2 * p.value\n",
    "\n",
    "    def forward(self, x, label_onehot):\n",
    "        eps = 1e-6\n",
    "        self.label_onehot = label_onehot\n",
    "        self.predict = self.sigmoid(x)\n",
    "        self.predict = np.clip(self.predict, a_max=1-eps, a_min=eps)  # 裁切\n",
    "        self.batch_size = self.predict.shape[0]\n",
    "        return -np.sum(label_onehot * np.log(self.predict) + (1 - label_onehot) * \n",
    "                        np.log(1 - self.predict)) / self.batch_size + self.decay_loss()\n",
    "    \n",
    "    def backward(self):\n",
    "        self.decay_backward()\n",
    "        return (self.predict - self.label_onehot) / self.batch_size\n",
    "    \n",
    "class SoftmaxCrossEntropy(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"SoftmaxCrossEntropy\")\n",
    "        \n",
    "    def softmax(self, x):\n",
    "        #return np.exp(x) / np.sum(np.exp(x), axis=1, keepdims=True)\n",
    "        max_x = np.max(x, axis=1, keepdims=True)\n",
    "        exp_x = np.exp(x - max_x)\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "    def forward(self, x, label_onehot):\n",
    "        eps = 1e-6\n",
    "        self.label_onehot = label_onehot\n",
    "        self.predict = self.softmax(x)\n",
    "        self.predict = np.clip(self.predict, a_max=1-eps, a_min=eps)  # 裁切\n",
    "        self.batch_size = self.predict.shape[0]\n",
    "        return -np.sum(label_onehot * np.log(self.predict)) / self.batch_size\n",
    "    \n",
    "    def backward(self):\n",
    "        return (self.predict - self.label_onehot) / self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# class Conv2d(Module):\n",
    "#     def __init__(self, in_feature, out_feature, kernel_size, padding=0, stride=1):\n",
    "#         super().__init__(\"Conv2d\")\n",
    "#         self.in_feature = in_feature\n",
    "#         self.out_feature = out_feature\n",
    "#         self.kernel_size = kernel_size\n",
    "#         self.padding = padding\n",
    "#         self.stride = stride\n",
    "#         self.kernel = Parameter(np.ones((out_feature, in_feature, kernel_size, kernel_size)))\n",
    "#         self.bias = Parameter(np.zeros((out_feature)))\n",
    "#         #initer = GaussInitializer(0, np.sqrt(2 / in_feature))  # np.sqrt(2 / input_feature)\n",
    "#         #initer.apply(self.kernel.value)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         self.in_shape = x.shape\n",
    "#         ib, ic, ih, iw = self.in_shape\n",
    "#         self.oh = (ih + self.padding * 2 - self.kernel_size) // self.stride + 1\n",
    "#         self.ow = (iw + self.padding * 2 - self.kernel_size) // self.stride + 1\n",
    "#         col_w = self.oh * self.ow\n",
    "#         col_h = self.kernel_size * self.kernel_size * self.in_feature\n",
    "#         self.column = np.zeros((col_h, col_w))\n",
    "#         self.output = np.zeros((ib, self.out_feature, self.oh, self.ow))\n",
    "#         khalf = self.kernel_size // 2\n",
    "#         self.kcol = self.kernel.value.reshape(self.out_feature, -1)\n",
    "#         for b in range(ib):\n",
    "#             for c in range(ic):\n",
    "#                 for oy in range(self.oh):\n",
    "#                     for ox in range(self.ow):\n",
    "#                         for ky in range(self.kernel_size):\n",
    "#                             for kx in range(self.kernel_size):\n",
    "#                                 column_y = ky * self.kernel_size + kx + c * self.kernel_size * self.kernel_size\n",
    "#                                 column_x = ox + oy * self.ow\n",
    "#                                 ix = ox * self.stride + kx - self.padding\n",
    "#                                 iy = oy * self.stride + ky - self.padding\n",
    "#                                 if ix >= 0 and iy >= 0 and ix < iw and iy < ih:\n",
    "#                                     self.column[column_y, column_x] = x[b, c, iy, ix]\n",
    "#             self.output[b] = (self.kcol @ self.column).reshape(self.out_feature, self.oh, self.ow) + self.bias.value.reshape(self.out_feature, 1, 1)\n",
    "#         return self.output\n",
    "    \n",
    "#     #AB = C  G\n",
    "#     #dB = A.T @ G\n",
    "#     #dA = G @ B.T\n",
    "#     def backward(self, G):\n",
    "        \n",
    "#         ib, ic, ih, iw = self.in_shape\n",
    "#         for b in range(ib):\n",
    "#             self.kernel.delta += (G[b].reshape(self.out_feature, -1) @ self.column.T).reshape(self.kernel.value.shape)\n",
    "    \n",
    "#         self.bias.delta += np.sum(G, axis=(0, 2, 3))\n",
    "#         self.Gout = np.zeros((self.in_shape))\n",
    "#         for b in range(ib):\n",
    "#             dcolumn = self.kcol.T @ G[b].reshape(self.out_feature, -1)\n",
    "            \n",
    "#             for c in range(ic):\n",
    "#                 for oy in range(self.oh):\n",
    "#                     for ox in range(self.ow):\n",
    "#                         for ky in range(self.kernel_size):\n",
    "#                             for kx in range(self.kernel_size):\n",
    "#                                 column_y = ky * self.kernel_size + kx + c * self.kernel_size * self.kernel_size\n",
    "#                                 column_x = ox + oy * self.ow\n",
    "#                                 ix = ox * self.stride + kx - self.padding\n",
    "#                                 iy = oy * self.stride + ky - self.padding\n",
    "#                                 if ix >= 0 and iy >= 0 and ix < iw and iy < ih:\n",
    "#                                     self.Gout[b, c, iy, ix] += dcolumn[column_y, column_x]\n",
    "#         return self.Gout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "conv = Conv2d(1, 2, 3, 1, 1)\n",
    "x = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "]).reshape(1, 1, 3, 3).astype(np.float32)\n",
    "x = np.repeat(x, 2, axis=0)\n",
    "x[1] *= 0.5\n",
    "o = conv(x)\n",
    "g = conv.backward(o)\n",
    "o, g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = np.ones((256, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.sum(x, axis=1, keepdims=True).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "$$ p(x) = \\frac{1}{\\sqrt{ 2 \\pi \\sigma^2 }}\n",
    "                     e^{ - \\frac{ (x - \\mu)^2 } {2 \\sigma^2} } $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, name, model, lr):\n",
    "        self.name = name\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "        self.params = model.params()\n",
    "                \n",
    "    def zero_grad(self):\n",
    "        for param in self.params:\n",
    "            param.zero_grad()\n",
    "            \n",
    "    def set_lr(self, lr):\n",
    "        self.lr = lr\n",
    "        \n",
    "class SGD(Optimizer):\n",
    "    def __init__(self, model, lr=1e-3):\n",
    "        super().__init__(\"SGD\", model, lr)\n",
    "    \n",
    "    def step(self):\n",
    "        for param in self.params:\n",
    "            param.value -= self.lr * param.delta\n",
    "            \n",
    "class SGDMomentum(Optimizer):\n",
    "    def __init__(self, model, lr=1e-3, momentum=0.9):\n",
    "        super().__init__(\"SGDMomentum\", model, lr)\n",
    "        self.momentum = momentum\n",
    "        \n",
    "        for param in self.params:\n",
    "            param.v = 0\n",
    "    \n",
    "    # 移动平均\n",
    "    def step(self):\n",
    "        for param in self.params:\n",
    "            param.v = self.momentum * param.v - self.lr * param.delta\n",
    "            param.value += param.v\n",
    "            \n",
    "class Adam(Optimizer):\n",
    "    def __init__(self, model, lr=1e-3, beta1=0.9, beta2=0.999, l2_regularization = 0):\n",
    "        super().__init__(\"Adam\", model, lr)\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.l2_regularization = l2_regularization\n",
    "        self.t = 0\n",
    "        \n",
    "        for param in self.params:\n",
    "            param.m = 0\n",
    "            param.v = 0\n",
    "            \n",
    "    # 指数移动平均\n",
    "    def step(self):\n",
    "        eps = 1e-8\n",
    "        self.t += 1\n",
    "        for param in self.params:\n",
    "            g = param.delta\n",
    "            param.m = self.beta1 * param.m + (1 - self.beta1) * g\n",
    "            param.v = self.beta2 * param.v + (1 - self.beta2) * g ** 2\n",
    "            mt_ = param.m / (1 - self.beta1 ** self.t)\n",
    "            vt_ = param.v / (1 - self.beta2 ** self.t)\n",
    "            param.value -= self.lr * mt_ / (np.sqrt(vt_) + eps) + self.l2_regularization * param.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Model(Module):\n",
    "    def __init__(self, num_feature, num_hidden, num_classes):\n",
    "        super().__init__(\"Model\")\n",
    "        self.backbone = ModuleList(\n",
    "            Conv2d(1, 16, 3, 0, 2),\n",
    "            ReLU(),\n",
    "            Conv2d(16, 8, 3, 0, 2),\n",
    "            ReLU(),\n",
    "            Conv2d(8, 8, 3, 0, 1),\n",
    "            ReLU(),\n",
    "            Flatten(),\n",
    "            Linear(num_feature, num_hidden),\n",
    "            ReLU(),\n",
    "            Dropout(),\n",
    "            Linear(num_hidden, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "    \n",
    "    def backward(self, G):\n",
    "        return self.backbone.backward(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "def estimate_val(predict, gt_labels, classes, loss_func):\n",
    "    plabel = predict.argmax(1)\n",
    "    positive = plabel == gt_labels\n",
    "    total_images = predict.shape[0]\n",
    "    accuracy = sum(positive) / total_images\n",
    "    return accuracy, loss_func(predict, one_hot(gt_labels, classes))\n",
    "\n",
    "def lr_schedule_cosine(lr_min, lr_max, per_epochs):\n",
    "    def compute(epoch):\n",
    "        return lr_min + 0.5 * (lr_max - lr_min) * (1 + np.cos(epoch / per_epochs * np.pi))\n",
    "    return compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(\"cat.jpg\")\n",
    "show = image.copy()\n",
    "image = cv2.resize(image, (28, 28))\n",
    "plt.imshow(image[..., ::-1])\n",
    "image = ((image / 255) - 0.5).astype(np.float32)\n",
    "image = image.transpose(2, 0, 1)[None]\n",
    "image.shape, show.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sx = 1 / 450\n",
    "sy = 1 / 324\n",
    "x, y, r, b = 41 * sx, 21 * sy, 210 * sx, 189 * sy\n",
    "#cv2.rectangle(show, (x,y), (r, b), (0, 255, 0), 2)\n",
    "#plt.imshow(show[..., ::-1])\n",
    "x, y, r, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Model(Module):\n",
    "    def __init__(self, num_feature, num_hidden, nreg):\n",
    "        super().__init__(\"Model\")\n",
    "        self.backbone = ModuleList(\n",
    "            Conv2d(3, 16, 3, 0, 2),\n",
    "            ReLU(),\n",
    "            Conv2d(16, 8, 3, 0, 2),\n",
    "            ReLU(),\n",
    "            Conv2d(8, 8, 3, 0, 1),\n",
    "            ReLU(),\n",
    "            Flatten(),\n",
    "            Linear(num_feature, num_hidden),\n",
    "            ReLU(),\n",
    "            Linear(num_hidden, nreg)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "    \n",
    "    def backward(self, G):\n",
    "        return self.backbone.backward(G)\n",
    "\n",
    "np.random.seed(3)\n",
    "lr = 1e-2\n",
    "data_dims = 128\n",
    "\n",
    "model = Model(data_dims, 64, 4)\n",
    "optim = Adam(model, lr)\n",
    "gt = np.array([x, y, r, b])\n",
    "\n",
    "for i in range(100):\n",
    "    predict = model(image)\n",
    "    loss = np.sum((gt - predict) ** 2) * 0.5\n",
    "    print(loss)\n",
    "\n",
    "    optim.zero_grad()\n",
    "    G = predict - gt\n",
    "    model.backward(G)\n",
    "    optim.step()   # 应用梯度，更新参数\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predict = model(image)\n",
    "predict, gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "h, w = show.shape[:2]\n",
    "nx, ny, nr, nb = predict[0] * np.array([w, h, w, h])\n",
    "nx, ny, nr, nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cv2.rectangle(show, (int(nx), int(ny)), (int(nr), int(nb)), (0, 255, 0), 2)\n",
    "plt.imshow(show[..., ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "classes = 10                  # 定义10个类别\n",
    "batch_size = 32              # 定义每个批次的大小\n",
    "epochs = 20                   # 退出策略，也就是最大把所有数据看10次\n",
    "lr = 1e-2\n",
    "numdata, _, _, _ = train_images.shape  # 60000, 784\n",
    "data_dims = 128\n",
    "\n",
    "# 定义dataloader和dataset，用于数据抓取\n",
    "train_data = DataLoader(Dataset(train_images, one_hot(train_labels, classes)), batch_size, shuffle=True)\n",
    "model = Model(data_dims, 64, classes)\n",
    "#loss_func = SoftmaxCrossEntropy()\n",
    "loss_func = SigmoidCrossEntropy(model.params(), 0)\n",
    "optim = Adam(model, lr)\n",
    "iters = 0   # 定义迭代次数，因为我们需要展示loss曲线，那么x将会是iters\n",
    "\n",
    "lr_schedule = {\n",
    "    5: 1e-3,\n",
    "    15: 1e-4,\n",
    "    18: 1e-5\n",
    "}\n",
    "\n",
    "# 开始进行epoch循环，总数是epochs次\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    if epoch in lr_schedule:\n",
    "        lr = lr_schedule[epoch]\n",
    "        optim.set_lr(lr)\n",
    "    \n",
    "    model.train()\n",
    "    # 对一个批次内的数据进行迭代，每一次迭代都是一个batch（即256）\n",
    "    for index, (images, labels) in enumerate(train_data):\n",
    "        \n",
    "        x = model(images)\n",
    "        \n",
    "        # 计算loss值\n",
    "        loss = loss_func(x, labels)\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        G = loss_func.backward()\n",
    "        model.backward(G)\n",
    "        optim.step()   # 应用梯度，更新参数\n",
    "        iters += 1\n",
    "        \n",
    "        print(f\"Iter {iters}, {epoch} / {epochs}, Loss {loss:.3f}, LR {lr:g}\")\n",
    "    \n",
    "    model.eval()\n",
    "    val_accuracy, val_loss = estimate_val(model(val_images), val_labels, classes, loss_func)\n",
    "    print(f\"Val set, Accuracy: {val_accuracy:.6f}, Loss: {val_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 今日总结\n",
    "1. Makefile的使用\n",
    "    - \\\\$\\@ 生成项  \\\\$\\< 依赖项第一个  \\\\$^ 依赖项的所有\n",
    "    - var := \\\\$(shell command)  执行command，结果赋值给var\n",
    "    - 生成项 : 依赖项1 依赖项2 依赖项n\n",
    "         - command\n",
    "    - \\\\$(patsubst src,dst,list)\n",
    "    - 数据类型，字符串，数组，数组以空格区分\n",
    "    - find . -name \"*.cpp\" 查找当前目录下的所有cpp文件\n",
    "    - %.o : %.cpp  通配\n",
    "2. 优化了程序结构\n",
    "    - 使用Layer的方式抽象每一个层\n",
    "    - 使用Model的方式抽象模型\n",
    "    - 使用Parameter抽象可训练参数\n",
    "    - 使用Optimizer抽象优化器\n",
    "    - 引入参数初始化器，高斯初始化\n",
    "    - 加入zero_grad，清空梯度，其实是摆设。多次迭代，一次更新时有用（etc. GAN、强化学习）\n",
    "3. 引入优化器\n",
    "    - Momentum SGD，动量SGD，移动平均，物理解释（算是合理的）是惯性，这个也很常用\n",
    "    - Adam，指数移动平均，这个很常用\n",
    "4. ReLU激活函数\n",
    "    - 在0点的导数，是不可导。可以指定为0或者1，自己去研究\n",
    "5. 没有了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 作业\n",
    "1. 周五24：00交\n",
    "2. 交什么？\n",
    "    - a. 实现老师今天总结的BP引入的内容（把这个程序打一遍）\n",
    "    - b. 要求精度大于0.965以上\n",
    "    - c. 精度第一的，考虑奖励一些东西"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}